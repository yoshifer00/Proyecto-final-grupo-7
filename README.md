# DQN Robot Navigation â€“ Grupo 7 (ROS 2 Jazzy)

Este repositorio implementa un entrenamiento de **navegaciÃ³n autÃ³noma** usando **Deep Q-Network (DQN)** para un robot mÃ³vil simulado en **Stage**, utilizando **ROS 2 Jazzy**.

El objetivo es que el robot aprenda a navegar hacia una meta evitando obstÃ¡culos a partir de informaciÃ³n de **LiDAR** y **odometrÃ­a**.

A diferencia de otros proyectos que usan frameworks pesados (TensorFlow / PyTorch), aquÃ­ se utiliza **scikit-learn** (`MLPRegressor`) para el agente DQN, lo que simplifica la integraciÃ³n directa con nodos de ROS sin conflictos de dependencias.

---

## ğŸ› ï¸ InstalaciÃ³n y dependencias

### Requisitos

* Ubuntu **24.04**
* **ROS 2 Jazzy** correctamente instalado y configurado

### Paquetes ROS necesarios

Instala los paquetes bÃ¡sicos para Stage y mensajes de navegaciÃ³n:

```bash
sudo apt install \
  ros-jazzy-stage-ros \
  ros-jazzy-navigation-msgs \
  ros-jazzy-geometry-msgs \
  ros-jazzy-sensor-msgs \
  ros-jazzy-nav-msgs \
  ros-jazzy-std-srvs
```

### Dependencias de Python

El agente DQN usa `scikit-learn` para la red neuronal:

```bash
sudo apt install python3-sklearn python3-numpy python3-matplotlib
```

---

## ğŸš€ EjecuciÃ³n del proyecto

### 1. ConstrucciÃ³n del workspace

Clona el repositorio dentro de un workspace de ROS 2:

```bash
mkdir -p ~/proyecto_ws/src
cd ~/proyecto_ws/src
git clone https://github.com/TU_USUARIO/dqn_robot_nav.git
```

Construye el workspace:

```bash
cd ~/proyecto_ws
colcon build
source install/setup.bash
```

---

### 2. EjecuciÃ³n del entrenamiento

âš ï¸ NecesitarÃ¡s **dos terminales** (recuerda hacer `source install/setup.bash` en ambas).

#### Terminal 1 â€“ Simulador Stage

```bash
ros2 launch stage_ros2 stage.launch.py
```

AsegÃºrate de que Stage estÃ© publicando en los tÃ³picos:

* `/base_scan`
* `/odom`

Puedes verificarlo con:

```bash
ros2 topic echo /base_scan
ros2 topic echo /odom
```

Si estos tÃ³picos no publican, el agente se quedarÃ¡ esperando datos.

---

#### Terminal 2 â€“ Entrenamiento DQN

```bash
ros2 launch dqn_robot_nav dqn_training.launch.py
```

Esto iniciarÃ¡ el entrenamiento del agente DQN y el reseteo automÃ¡tico del robot en Stage.

---

##  Detalles del agente DQN

###  Espacio de acciones

Acciones discretas utilizadas por el agente:

| AcciÃ³n | Movimiento                |
| -----: | ------------------------- |
|      0 | Avanzar                   |
|      1 | Girar izquierda           |
|      2 | Girar derecha             |
|      3 | Avanzar + girar izquierda |
|      4 | Avanzar + girar derecha   |

Las velocidades lineales y angulares pueden ajustarse en `environment.py`.

> ğŸ’¡ Si el robot se queda girando en un mismo lugar, revisa la funciÃ³n de recompensa en `environment.py` (penalizaciÃ³n por rotaciÃ³n y recompensa por progreso).

---

## ğŸ“‚ Estructura real del repositorio

```text
dqn_robot_nav/
â”œâ”€â”€ dqn_agent.py          # Agente DQN (MLPRegressor, replay buffer, target network)
â”œâ”€â”€ environment.py        # Entorno ROS 2 (StageEnv)
â”œâ”€â”€ state_processor.py    # Procesamiento del estado (LiDAR + meta)
â”œâ”€â”€ train_node.py         # Nodo principal de entrenamiento
â”œâ”€â”€ reset_stage.py        # Wrapper para reset de Stage y odometrÃ­a
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ dqn_training.launch.py
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Resultados

Durante el entrenamiento se generan automÃ¡ticamente carpetas de resultados:

* `results_YYYYMMDD_*/`

  * `*.pkl` â†’ modelo entrenado
  * `training_results.png` â†’ grÃ¡fica de recompensa por episodio

Estas grÃ¡ficas permiten evaluar si el agente estÃ¡ aprendiendo o si la recompensa estÃ¡ estancada.

---


## ğŸ‘¥ Autores

* Daniel Callata
* Jhoselin Fernandez
* Patricio Flores
