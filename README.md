# Proyecto-final-grupo-7
# DQN Robot Navigation with Stage (ROS 2)

Este repositorio implementa un **entrenamiento de navegaciÃ³n autÃ³noma usando Deep Q-Network (DQN)** para un robot mÃ³vil simulado en **Stage**, utilizando **ROS 2 Jazzy** y **Python 3.12**.

El objetivo es que el robot aprenda a navegar hacia una meta evitando obstÃ¡culos a partir de informaciÃ³n de LiDAR y odometrÃ­a.

---

## ğŸ“¦ Contenido del proyecto

```
dqn_robot_nav/
â”œâ”€â”€ dqn_agent.py        # Agente DQN (MLPRegressor + replay + target network)
â”œâ”€â”€ environment.py      # Entorno ROS2 (StageEnv)
â”œâ”€â”€ state_processor.py  # Procesamiento del estado (LiDAR + goal)
â”œâ”€â”€ train_node.py       # Nodo principal de entrenamiento
â”œâ”€â”€ reset_stage.py      # Wrapper para reset de Stage y odometrÃ­a
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ dqn_training.launch.py
â””â”€â”€ README.md
```

---

## âš™ï¸ Requisitos

### Sistema
- **Ubuntu 24.04**
- **ROS 2 Jazzy**
- **Python 3.12**

### Dependencias ROS
```bash
sudo apt install \
  ros-jazzy-stage-ros \
  ros-jazzy-navigation-msgs \
  ros-jazzy-geometry-msgs \
  ros-jazzy-sensor-msgs \
  ros-jazzy-nav-msgs \
  ros-jazzy-std-srvs
```

### Dependencias Python
```bash
sudo apt install python3-sklearn python3-numpy python3-matplotlib
```

> âš ï¸ Se usa **scikit-learn** en lugar de PyTorch/TensorFlow para compatibilidad con ROS 2 Jazzy.

---

## ğŸ§± ConstrucciÃ³n del workspace

Clona el repositorio dentro de tu workspace ROS 2:

```bash
cd ~/proyecto_ws/src
git clone https://github.com/TU_USUARIO/dqn_robot_nav.git
```

Construye el workspace:

```bash
cd ~/proyecto_ws
colcon build --packages-select dqn_robot_nav
source install/setup.bash
```

---

## â–¶ï¸ EjecuciÃ³n del entrenamiento

### 1ï¸âƒ£ Lanzar Stage (mapa y robot)

AsegÃºrate de tener un mundo de Stage corriendo que publique:
- `/base_scan` (LaserScan)
- `/odom`

Ejemplo:
```bash
ros2 launch stage_ros2 stage.launch.py
```

---

### 2ï¸âƒ£ Ejecutar el entrenamiento DQN

En otra terminal (con el workspace sourceado):

```bash
source ~/proyecto_ws/install/setup.bash
ros2 launch dqn_robot_nav dqn_training.launch.py
```

Esto lanzarÃ¡:
- `reset_stage.py` â†’ reset de Stage + odometrÃ­a
- `train_node.py` â†’ entrenamiento DQN

---

## ğŸ“Š Resultados del entrenamiento

Durante el entrenamiento se crea automÃ¡ticamente una carpeta:

```
results_YYYYMMDD_HHMMSS/
â”œâ”€â”€ model_episode_50.pkl
â”œâ”€â”€ model_episode_100.pkl
â”œâ”€â”€ model_final.pkl
â””â”€â”€ training_results.png
```

Incluye:
- ğŸ“ˆ Curvas de recompensa
- â±ï¸ Pasos por episodio
- âœ… Tasa de Ã©xito

---

## ğŸ§  Estado del DQN

El estado del agente es:

```
[ LiDAR_bins (n) | distancia_a_goal | Ã¡ngulo_a_goal ]
```

Por defecto:
- `n_lidar_bins = 10`
- `state_size = 12`

---

## ğŸ¯ Espacio de acciones

Acciones discretas:

| AcciÃ³n | Movimiento |
|------|------------|
| 0 | Avanzar |
| 1 | Girar izquierda |
| 2 | Girar derecha |
| 3 | Avanzar + izquierda |
| 4 | Avanzar + derecha |

Las velocidades se pueden ajustar en `environment.py`.

---

## ğŸ› ï¸ Ajustes recomendados

Si el robot gira en cÃ­rculos:
- Aumentar recompensa por progreso
- Penalizar giros repetidos
- Reducir velocidad angular
- Incrementar `epsilon_min`
- Usar mÃ¡s bins de LiDAR

Estos ajustes estÃ¡n documentados directamente en el cÃ³digo.

---

## ğŸ§ª Notas importantes

- El entrenamiento es **online** y puede ser lento.
- Se recomienda entrenar sin visualizaciÃ³n pesada.
- Stage puede tardar en publicar `/base_scan` tras un reset.

---

## ğŸ‘©â€ğŸ’» Autor

Proyecto desarrollado como experimento acadÃ©mico de **aprendizaje por refuerzo aplicado a robÃ³tica mÃ³vil con ROS 2**.

---

## ğŸ“œ Licencia

MIT License

---

Si tienes dudas o quieres extender el proyecto (Double DQN, PPO, PyTorch, Gazebo, etc.), Â¡adelante! ğŸš€

